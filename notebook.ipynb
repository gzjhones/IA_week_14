{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias del entrenamiento del modelo\n",
    "!pip install torch torchvision matplotlib numpy pillow torchsummary tensorboard\n",
    "\n",
    "# Dependencias de la API\n",
    "!pip install zipfile36 flask flask-cors pyngrok torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from torchsummary import summary\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "import shutil\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del dispositivo (GPU si está disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica si existen los directorios\n",
    "need_extract = False\n",
    "for folder in ['datasets', 'examples']:\n",
    "    if not os.path.exists(folder):\n",
    "        need_extract = True\n",
    "        break\n",
    "\n",
    "if need_extract:\n",
    "    zip_path = './folders.zip'  \n",
    "    if os.path.exists(zip_path):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(\"¡Carpetas extraídas!\")\n",
    "    else:\n",
    "        print(\"No se encontró el archivo folders.zip.\")\n",
    "else:\n",
    "    print(\"Los directorios 'datasets' y 'examples' ya existen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina la carpeta si existe\n",
    "for folder in ['datasets/train/.ipynb_checkpoints', 'datasets/val/.ipynb_checkpoints']:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las transformaciones para los conjuntos de datos de entrenamiento y validación\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las rutas a los directorios de datos\n",
    "data_dir = 'datasets/train'\n",
    "val_dir = 'datasets/val'\n",
    "# Define el porcentaje de datos a utilizar (por ejemplo, 50%)\n",
    "portion_train = 1\n",
    "portion_val = 1\n",
    "\n",
    "# Cargar los conjuntos de datos de entrenamiento y validación\n",
    "full_train_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "full_val_dataset = datasets.ImageFolder(val_dir, data_transforms['val'])\n",
    "\n",
    "# Calcular el número de muestras a usar según el porcentaje\n",
    "num_train_samples = int(len(full_train_dataset) * portion_train)\n",
    "num_val_samples = int(len(full_val_dataset) * portion_val)\n",
    "\n",
    "# Crear un subset de los datos\n",
    "train_indices = torch.randperm(len(full_train_dataset)).tolist()[:num_train_samples]\n",
    "val_indices = torch.randperm(len(full_val_dataset)).tolist()[:num_val_samples]\n",
    "\n",
    "image_datasets = {\n",
    "    'train': torch.utils.data.Subset(full_train_dataset, train_indices),\n",
    "    'val': torch.utils.data.Subset(full_val_dataset, val_indices)\n",
    "}\n",
    "\n",
    "# Crear DataLoaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "# Obtener las clases\n",
    "class_names = full_train_dataset.classes\n",
    "\n",
    "# Obtener el tamaño de los conjuntos de datos\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar un modelo pre-entrenado (ResNet18) y ajustar las últimas capas\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el modelo\n",
    "def train_model(model, criterion, optimizer, num_epochs=5):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "model = train_model(model, criterion, optimizer, num_epochs=5)\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir una imagen\n",
    "def predict_image(image_path):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path)\n",
    "    image = data_transforms['val'](image).unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    return class_names[preds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta a la carpeta que contiene las imágenes\n",
    "folder_path = 'examples'\n",
    "\n",
    "# Obtener una lista de todas las imágenes en la carpeta\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Número de imágenes\n",
    "num_images = len(image_files)\n",
    "\n",
    "# Calcular el número de filas y columnas para el mosaico\n",
    "cols = 3  # Puedes ajustar esto para tener más o menos columnas\n",
    "rows = math.ceil(num_images / cols)\n",
    "\n",
    "# Crear una figura con subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "\n",
    "# Aplanar los ejes para iterar fácilmente si hay más de una fila\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterar sobre las imágenes y mostrarlas en el mosaico\n",
    "for i, filename in enumerate(image_files):\n",
    "    image_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Hacer la predicción\n",
    "    prediction = predict_image(image_path)\n",
    "    \n",
    "    # Abrir la imagen\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Mostrar la imagen junto con la predicción\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f'Predicción: {prediction}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Eliminar los ejes sobrantes si hay menos imágenes que subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "ngrok.set_auth_token(\"ngrok_token\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load('model.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "    file = request.files['file']\n",
    "    image = Image.open(io.BytesIO(file.read())).convert('RGB')\n",
    "    image = data_transforms(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    prediction = class_names[preds[0].item()]\n",
    "    return jsonify({'prediction': prediction})\n",
    "\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\" * ngrok URL:\", public_url)\n",
    "app.run(port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_041124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
